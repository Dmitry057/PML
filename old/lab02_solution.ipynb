{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical machine learning and deep learning. Lab 2\n",
    "# MLOPS part 1\n",
    "\n",
    "### No competition this week!\n",
    "\n",
    "On this lab, we continue exploring ClearML framework. In particular, we will learn how to use ClearML to:\n",
    "- track experiments \n",
    "- run hyperparameters optimization\n",
    "- share experiments with other users\n",
    "- detect data drift\n",
    "- deploy clearml server locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clearml in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: attrs>=18.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (25.3.0)\n",
      "Requirement already satisfied: furl>=2.0.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.1.4)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (4.24.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.2.6)\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.3.7.post1)\n",
      "Requirement already satisfied: psutil>=3.4.2 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (7.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.9.0.post0)\n",
      "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.10.1)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (6.0.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.5.0)\n",
      "Requirement already satisfied: Pillow>=10.3.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (11.2.1)\n",
      "Requirement already satisfied: referencing<0.40 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (0.36.2)\n",
      "Requirement already satisfied: requests>=2.32.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from clearml) (2.32.4)\n",
      "Requirement already satisfied: rpds-py>=0.7.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from referencing<0.40->clearml) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from referencing<0.40->clearml) (4.14.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (2025.6.15)\n",
      "zsh:1: no matches found: alibi-detect[torch]\n"
     ]
    }
   ],
   "source": [
    "!pip install clearml\n",
    "!pip install alibi-detect[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. (Duplication of the previous lab) ClearML installation\n",
    "\n",
    "1) Sign up in  [ClearMl](https://clear.ml)\n",
    "2) Install clearml as python package: pip install clearml\n",
    "3) Get [credentials](https://app.clear.ml/settings/workspace-configuration) to connect your notebook with remote server. When creating new credentials, pick Jupyter notebook tab.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Put these env variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=... # Enter your api access key\n",
    "%env CLEARML_API_SECRET_KEY=... # Enter your secret key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Run the following cell to initialize ClearML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML SDK setup process\n",
      "Configuration file already exists: /Users/dmitry057/clearml.conf\n",
      "Leaving setup, feel free to edit the configuration file.\n"
     ]
    }
   ],
   "source": [
    "!clearml-init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tracking of CNN training on CIFAR10\n",
    "\n",
    "We start from the similar pipeline as on the previous lab. Fisrt, you're asking to train a ResNet18 on CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 ClearML init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from clearml import Task\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: overwriting (reusing) task id=7989e27ef26c415b826665d5e6a8f069\n",
      "2025-09-03 13:35:05,565 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "2025-09-03 13:35:05,596 - clearml.Repository Detection - WARNING - Can't get url information for git repo in /Users/dmitry057/Projects/Innopolis/PML\n",
      "2025-09-03 13:35:05,643 - clearml.Repository Detection - WARNING - Can't get branch information for git repo in /Users/dmitry057/Projects/Innopolis/PML\n",
      "2025-09-03 13:35:05,665 - clearml.Repository Detection - WARNING - Can't get commit information for git repo in /Users/dmitry057/Projects/Innopolis/PML\n",
      "2025-09-03 13:35:05,757 - clearml.Repository Detection - WARNING - Can't get diff information for git repo in /Users/dmitry057/Projects/Innopolis/PML\n",
      "ClearML results page: https://clearml.touchtopnotch.com/projects/ae77eb2837d4412ca405daf2291a64b0/experiments/7989e27ef26c415b826665d5e6a8f069/output/log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEARML-SERVER new package available: UPGRADE to v2.2.0 is recommended!\n",
      "Release Notes:\n",
      "## New Features and Improvements\n",
      "\n",
      "- Update fixed users password note in apiserver.conf (#284, thanks @djiboshin!)\n",
      "- New UI global search including quick filters ([ClearML #1041](https://github.com/allegroai/clearml/issues/1041))\n",
      "- Add persistent UI plot properties: Plot settings (e.g. logarithmic/linear scale, hover mode) are retained across project tasks\n",
      "- Add option to hide original graph when smoothing is enabled in UI plot ([ClearML #1400](https://github.com/clearml/clearml/issues/1400))\n",
      "- Add persistent UI table details view ([ClearML Web #105](https://github.com/clearml/clearml-web/issues/105)) \n",
      "- Add search bar to UI Queues table\n",
      "\n",
      "## Bug Fixes\n",
      "\n",
      "- Fix embedded UI task comparison plot legends unnecessarily display task ID suffixes ([ClearML #1344](https://github.com/clearml/clearml/issues/1344))\n",
      "- Fix UI task dataset alias does not link to dataset page ([ClearML #735](https://github.com/clearml/clearml/issues/735))\n",
      "- UI task comparison parallel coordinate view: \n",
      "  - Fix color selector in legend does not display currently assigned color\n",
      "  - Fix embedded plot does not display plot legend\n",
      "  - Fix full screen missing legend and title, and displaying all graphs in same color\n",
      "- UI Plots:\n",
      "  - Fix x-axis units are not updated after selection is modified\n",
      "  - Fix UI plot \"Show closest data\" toggle not displaying in Plotly 2D and 3D scatter plots\n",
      "  - Fix highlight lines for \"show closest data\" function in UI 3D plot difficult to see in dark mode\n",
      "  - Fix plotly pointcloud is displayed monochromatically in UI plots ([ClearML #1428](https://github.com/clearml/clearml/issues/1428))\n",
      "  - Fix embedded plots sometimes fail to display\n",
      "- Queues:\n",
      "  - Fix UI queue creation modal allows invalid display name input \n",
      "  - Fix queue display name is updated after modification in UI Orchestration > Queues page\n",
      "- Fix project path indicator not displaying in UI project card's \n",
      "- Fix refreshing UI Model Endpoints > Loading tab navigates to another tab\n",
      "- Fix UI Dataset navigation bar sometimes disappears\n",
      "- Fix UI object table is sometimes not displayed in info panel view\n",
      "- Fix UI Settings API credential labels sometimes disappear \n",
      "- Fix default output destination indicator not displaying in UI project cards \n",
      "- Fix \"Clear Filters\" functionality sometimes does not work in UI task scalar comparison\n",
      "- Fix UI report preview sometimes does not load\n",
      "- Fix UI tables' Project column filter does not list all projects\n",
      "- Fix UI \"Create Project\" modal sometimes allows for creation of project with invalid date\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "2025-09-03 13:39:31,914 - clearml.Task - WARNING - ### TASK STOPPED - USER ABORTED - STATUS CHANGED ###\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClearML task\n",
    "task = Task.init(\n",
    "    project_name='Cifar10',\n",
    "    task_name='ResNet18_Training_Base',\n",
    "    task_type=Task.TaskTypes.training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClearML allows to track hyper‑parameters as well. We're going to tune them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = task.get_parameters().get('learning_rate', 0.01)\n",
    "wd = task.get_parameters().get('weight_decay', 5e-4)\n",
    "logger = task.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Let's start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root='./data', train=True,\n",
    "                            download=True, transform=transform_train)\n",
    "val_ds   = datasets.CIFAR10(root='./data', train=False,\n",
    "                            download=True, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "hp_optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HyperParameterOptimizer' object has no attribute 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m()\n\u001b[1;32m     17\u001b[0m batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HyperParameterOptimizer' object has no attribute 'step'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "epochs = 10\n",
    "for epoch in (bar := tqdm(range(epochs))):\n",
    "    model.train()\n",
    "    batch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        hp_optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        hp_optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(targets).sum().item()\n",
    "        total += inputs.size(0)\n",
    "\n",
    "\n",
    "    train_loss = batch_loss / total\n",
    "    acc_train = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "            total += inputs.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    acc_val = correct / total\n",
    "\n",
    "    # Log to ClearML\n",
    "    logger.report_scalar(title='train/accuracy',\n",
    "                         series='epoch', value=acc_train, iteration=epoch)\n",
    "    logger.report_scalar(title='val/accuracy',\n",
    "                         series='epoch', value=acc_val, iteration=epoch)\n",
    "    bar.set_description(f'Train acc: {acc_train:.4f} | Val acc: {acc_val:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Hyperparameters tuning\n",
    "\n",
    "The training seems fine, but you may notice that we took the hyperparameters a bit randomly. Now we're going to tune them using ClearML's hyperparameters optimization feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: tomli in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [optuna]2m3/4\u001b[0m [optuna]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 alembic-1.16.5 colorlog-6.9.0 optuna-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 13:36:29,886 - clearml.task - WARNING - Requirement ignored, Task.add_requirements() must be called before Task.init()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages/clearml/binding/import_bind.py:64: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  mod = builtins.__org_import__(name, globals=globals, locals=locals, fromlist=fromlist, level=level)\n"
     ]
    }
   ],
   "source": [
    "# A few more imports\n",
    "from clearml.automation import HyperParameterOptimizer\n",
    "from clearml.automation import UniformParameterRange, UniformIntegerParameterRange\n",
    "from clearml.automation.optuna import OptimizerOptuna\n",
    "from clearml import Task\n",
    "\n",
    "# Create a new optimizer task (just a controller, not the actual training)\n",
    "optim_task = Task.create(\n",
    "    project_name='Cifar10',\n",
    "    task_name='ResNet18_HPO',\n",
    "    task_type=Task.TaskTypes.optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space\n",
    "hyper_parameters = [\n",
    "    UniformParameterRange('learning_rate',      min_value=1e-4,  max_value=1e-1,   step_size=0.01),\n",
    "    UniformIntegerParameterRange('batch_size',  min_value=64,    max_value=128,    step_size=64),\n",
    "    UniformParameterRange('weight_decay',       min_value=0,     max_value=1e-2,   step_size=1e-3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-03 13:36:38,780 - clearml.automation.optimization - WARNING - Could not find requested hyper-parameters ['learning_rate', 'batch_size', 'weight_decay'] on base task 7989e27ef26c415b826665d5e6a8f069\n",
      "2025-09-03 13:36:38,948 - clearml.automation.optimization - WARNING - Could not find requested metric [('val/accuracy', 'epoch')] report on base task 7989e27ef26c415b826665d5e6a8f069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 13:36:38,949] A new study created in memory with name: 7989e27ef26c415b826665d5e6a8f069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO started – view the results in the ClearML UI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages/clearml/automation/optuna/optuna.py:52: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  parameter_override[name] = suggest(name=name, **params)\n",
      "/Users/dmitry057/Projects/DeepL/archi-ve/FreeCAD/.conda/ml/lib/python3.10/site-packages/optuna/distributions.py:687: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.01, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0901].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #0 completed, sleeping for 0.25 minutes\n",
      "2025-09-03 13:36:40,443 - clearml.automation.optimization - INFO - Creating new Task: {'learning_rate': 0.0301, 'batch_size': 64, 'weight_decay': 0.005}\n",
      "2025-09-03 13:36:41,022 - clearml.automation.optimization - INFO - Creating new Task: {'learning_rate': 0.07010000000000001, 'batch_size': 64, 'weight_decay': 0.001}\n",
      "2025-09-03 13:36:41,731 - clearml.automation.optimization - INFO - Creating new Task: {'learning_rate': 0.0001, 'batch_size': 128, 'weight_decay': 0.005}\n",
      "2025-09-03 13:36:42,172 - clearml.automation.optimization - INFO - Creating new Task: {'learning_rate': 0.0201, 'batch_size': 128, 'weight_decay': 0.001}\n",
      "Progress report #1 completed, sleeping for 5.0 minutes\n"
     ]
    }
   ],
   "source": [
    "# Hyper‑parameter optimizer instance\n",
    "optimizer = HyperParameterOptimizer(\n",
    "    base_task_id=task.id, # specify the id of previous task\n",
    "    hyper_parameters=hyper_parameters,\n",
    "    objective_metric_title='val/accuracy',  # we want to **maximize** validation accuracy\n",
    "    objective_metric_series='epoch',\n",
    "    objective_metric_sign='max',\n",
    "    optimizer_class=OptimizerOptuna,\n",
    "\n",
    "    # how many tasks to launch at a time\n",
    "    max_number_of_concurrent_tasks=4,\n",
    "    max_iteration_per_job=100,\n",
    "    # optional time limits (seconds)\n",
    "    optimization_time_limit=600., # 10 mins for the whole sweep\n",
    "    compute_time_limit=300.,      # 5 mins per task\n",
    "    total_max_jobs=10,            # 30 different hyper‑parameter combos\n",
    ")\n",
    "\n",
    "# Start the sweep (runs locally and pushes tasks to the queue)\n",
    "optimizer.start()    \n",
    "print(f'HPO started – view the results in the ClearML UI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [the documentation](https://clear.ml/docs/latest/docs/webapp/applications/apps_hpo/) to learn more about hyperparameters optimization and configure your own parameters of grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: run the code above and tune the hyperparameters. Optionally, you can share the training results with your friend(s). Open ClearML UI, find the project `Cifar10`, task `ResNet18_Training_Base:(some hyperparameters)`, click on it and create a sharable link in `Share` tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detecting data drift\n",
    "\n",
    "Data drift - a change in the distribution of the data that a model is trained on. It can happen for example when a model is trained on new data, or when the data is collected at a different time.\n",
    "\n",
    "ClearML actually is not able to detect data drift by itself, but we can use [alibi-detect](https://alibi-detect.readthedocs.io/en/latest/) to detect it.\n",
    "\n",
    "Alibi framework provides variuos methods for detection of data corruption and data drift. On this lab, we will use the Learned Kernel method.  It is closely related to the [classifier drift detector](https://docs.seldon.io/projects/alibi-detect/en/latest/cd/methods/classifierdrift.html) which trains a classifier to discriminate between instances from the reference window and instances from the test window. The difference here is that we train a kernel to output high similarity on instances from the same window and low similarity between instances from different windows. If this is possible in a generalisable manner then drift must have occured.\n",
    "\n",
    "On practice, Learned Kernel method means the training of data drift classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading CIFAR10 and CIFAR10C\n",
    "\n",
    "We already have CIFAR10 dataset loaded from torch. However, for simplicity of the example, we'll load a `tensorflow` version of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from alibi_detect.datasets import fetch_cifar10c, corruption_types_cifar10c\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = y_train.astype('int64').reshape(-1,)\n",
    "y_test = y_test.astype('int64').reshape(-1,)\n",
    "\n",
    "# Extract data with some corruptions\n",
    "corruption = ['gaussian_noise', 'motion_blur', 'brightness', 'pixelate']\n",
    "X_corr, y_corr = fetch_cifar10c(corruption=corruption, severity=5, return_X_y=True)\n",
    "X_corr = X_corr.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a random half of the test data as a reference window and the other half as a test window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_test = X_test.shape[0]\n",
    "idx = np.random.choice(n_test, size=n_test // 2, replace=False)\n",
    "idx_h0 = np.delete(np.arange(n_test), idx, axis=0)\n",
    "X_ref, y_ref = X_test[idx], y_test[idx]\n",
    "X_h0, y_h0 = X_test[idx_h0], y_test[idx_h0]\n",
    "print(X_ref.shape, X_h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute to NCHW\n",
    "def permute_c(x):\n",
    "    return np.transpose(x.astype(np.float32), (0, 3, 1, 2))\n",
    "\n",
    "n_corr = len(corruption)\n",
    "X_c = [X_corr[i * n_test:(i + 1) * n_test] for i in range(n_corr)]\n",
    "\n",
    "X_ref_pt = permute_c(X_ref)\n",
    "X_h0_pt = permute_c(X_h0)\n",
    "X_c_pt = [permute_c(xc) for xc in X_c]\n",
    "print(X_ref_pt.shape, X_h0_pt.shape, X_c_pt[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training Learned Kernel Drift detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define some kernel projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.utils.pytorch.kernels import DeepKernel\n",
    "\n",
    "\n",
    "proj = nn.Sequential(\n",
    "    nn.Conv2d(3, 8, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(8, 16, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    ").to(device)\n",
    "\n",
    "kernel = DeepKernel(proj, eps=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need to past the kernel to the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import LearnedKernelDrift\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "\n",
    "cd = LearnedKernelDrift(X_ref_pt, kernel, backend='pytorch', p_val=.05, epochs=4)\n",
    "\n",
    "# Save detector\n",
    "filepath = 'torch_detector'\n",
    "save_detector(cd, filepath)\n",
    "\n",
    "# Load detector\n",
    "cd = load_detector(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare the corrupted and original CIFAR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(cd, x_h0, x_corr, corruption):\n",
    "    labels = ['No!', 'Yes!']\n",
    "    preds = cd.predict(x_h0)\n",
    "    print('No corruption')\n",
    "    print('Drift? {}'.format(labels[preds['data']['is_drift']]))\n",
    "    print(f'p-value: {preds[\"data\"][\"p_val\"]:.3f}')\n",
    "\n",
    "    if isinstance(x_corr, list):\n",
    "        for x, c in zip(x_corr, corruption):\n",
    "            preds = cd.predict(x)\n",
    "            print('')\n",
    "            print(f'Corruption type: {c}')\n",
    "            print('Drift? {}'.format(labels[preds['data']['is_drift']]))\n",
    "            print(f'p-value: {preds[\"data\"][\"p_val\"]:.3f}')\n",
    "\n",
    "make_predictions(cd, X_h0_pt, X_c_pt, corruption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: try to train a ClassifierDrift detector. Is the result on the corrution types the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ClearML Server\n",
    "\n",
    "ClearML allows to track experiments in two ways: locally and from the cloud. Because of regular IP blocks, we have to install and run ClearML locally. For that we need to install **clearml-server**.\n",
    "\n",
    "\n",
    "The easiest way to deploy the server is to run docker. Follow [this instruction](https://clear.ml/docs/latest/docs/deploying_clearml/clearml_server_linux_mac/) to deploy the server.\n",
    "\n",
    "**Task**: try to deploy the server locally and run the code above again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
